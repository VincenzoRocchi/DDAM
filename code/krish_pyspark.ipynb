{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\python\\envs\\ddam\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\python\\envs\\ddam\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: tqdm in c:\\python\\envs\\ddam\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\python\\envs\\ddam\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pandas in c:\\python\\envs\\ddam\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\python\\envs\\ddam\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\envs\\ddam\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\envs\\ddam\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python\\envs\\ddam\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\envs\\ddam\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install tqdm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28cfa567610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"spark\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas vs Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_ID</th>\n",
       "      <th>Brew_Date</th>\n",
       "      <th>Beer_Style</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fermentation_Time</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>pH_Level</th>\n",
       "      <th>Gravity</th>\n",
       "      <th>Alcohol_Content</th>\n",
       "      <th>Bitterness</th>\n",
       "      <th>Color</th>\n",
       "      <th>Ingredient_Ratio</th>\n",
       "      <th>Volume_Produced</th>\n",
       "      <th>Total_Sales</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Brewhouse_Efficiency</th>\n",
       "      <th>Loss_During_Brewing</th>\n",
       "      <th>Loss_During_Fermentation</th>\n",
       "      <th>Loss_During_Bottling_Kegging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7870796</td>\n",
       "      <td>2020-01-01 00:00:19</td>\n",
       "      <td>Wheat Beer</td>\n",
       "      <td>Kegs</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>16</td>\n",
       "      <td>24.204251</td>\n",
       "      <td>5.289845</td>\n",
       "      <td>1.039504</td>\n",
       "      <td>5.370842</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1:0.32:0.16</td>\n",
       "      <td>4666</td>\n",
       "      <td>2664.759345</td>\n",
       "      <td>8.577016</td>\n",
       "      <td>89.195882</td>\n",
       "      <td>4.104988</td>\n",
       "      <td>3.235485</td>\n",
       "      <td>4.663204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9810411</td>\n",
       "      <td>2020-01-01 00:00:31</td>\n",
       "      <td>Sour</td>\n",
       "      <td>Kegs</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>13</td>\n",
       "      <td>18.086763</td>\n",
       "      <td>5.275643</td>\n",
       "      <td>1.059819</td>\n",
       "      <td>5.096053</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>1:0.39:0.24</td>\n",
       "      <td>832</td>\n",
       "      <td>9758.801062</td>\n",
       "      <td>7.420541</td>\n",
       "      <td>72.480915</td>\n",
       "      <td>2.676528</td>\n",
       "      <td>4.246129</td>\n",
       "      <td>2.044358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2623342</td>\n",
       "      <td>2020-01-01 00:00:40</td>\n",
       "      <td>Wheat Beer</td>\n",
       "      <td>Kegs</td>\n",
       "      <td>Malleswaram</td>\n",
       "      <td>12</td>\n",
       "      <td>15.539333</td>\n",
       "      <td>4.778016</td>\n",
       "      <td>1.037476</td>\n",
       "      <td>4.824737</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1:0.35:0.16</td>\n",
       "      <td>2115</td>\n",
       "      <td>11721.087016</td>\n",
       "      <td>8.451365</td>\n",
       "      <td>86.322144</td>\n",
       "      <td>3.299894</td>\n",
       "      <td>3.109440</td>\n",
       "      <td>3.033880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8114651</td>\n",
       "      <td>2020-01-01 00:01:37</td>\n",
       "      <td>Ale</td>\n",
       "      <td>Kegs</td>\n",
       "      <td>Rajajinagar</td>\n",
       "      <td>17</td>\n",
       "      <td>16.418489</td>\n",
       "      <td>5.345261</td>\n",
       "      <td>1.052431</td>\n",
       "      <td>5.509243</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>1:0.35:0.15</td>\n",
       "      <td>3173</td>\n",
       "      <td>12050.177463</td>\n",
       "      <td>9.671859</td>\n",
       "      <td>83.094940</td>\n",
       "      <td>2.136055</td>\n",
       "      <td>4.634254</td>\n",
       "      <td>1.489889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4579587</td>\n",
       "      <td>2020-01-01 00:01:43</td>\n",
       "      <td>Stout</td>\n",
       "      <td>Cans</td>\n",
       "      <td>Marathahalli</td>\n",
       "      <td>18</td>\n",
       "      <td>19.144908</td>\n",
       "      <td>4.861854</td>\n",
       "      <td>1.054296</td>\n",
       "      <td>5.133625</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>1:0.46:0.11</td>\n",
       "      <td>4449</td>\n",
       "      <td>5515.077465</td>\n",
       "      <td>7.895334</td>\n",
       "      <td>88.625833</td>\n",
       "      <td>4.491724</td>\n",
       "      <td>2.183389</td>\n",
       "      <td>2.990630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch_ID            Brew_Date  Beer_Style   SKU      Location  \\\n",
       "0   7870796  2020-01-01 00:00:19  Wheat Beer  Kegs    Whitefield   \n",
       "1   9810411  2020-01-01 00:00:31        Sour  Kegs    Whitefield   \n",
       "2   2623342  2020-01-01 00:00:40  Wheat Beer  Kegs   Malleswaram   \n",
       "3   8114651  2020-01-01 00:01:37         Ale  Kegs   Rajajinagar   \n",
       "4   4579587  2020-01-01 00:01:43       Stout  Cans  Marathahalli   \n",
       "\n",
       "   Fermentation_Time  Temperature  pH_Level   Gravity  Alcohol_Content  \\\n",
       "0                 16    24.204251  5.289845  1.039504         5.370842   \n",
       "1                 13    18.086763  5.275643  1.059819         5.096053   \n",
       "2                 12    15.539333  4.778016  1.037476         4.824737   \n",
       "3                 17    16.418489  5.345261  1.052431         5.509243   \n",
       "4                 18    19.144908  4.861854  1.054296         5.133625   \n",
       "\n",
       "   Bitterness  Color Ingredient_Ratio  Volume_Produced   Total_Sales  \\\n",
       "0          20      5      1:0.32:0.16             4666   2664.759345   \n",
       "1          36     14      1:0.39:0.24              832   9758.801062   \n",
       "2          30     10      1:0.35:0.16             2115  11721.087016   \n",
       "3          48     18      1:0.35:0.15             3173  12050.177463   \n",
       "4          57     13      1:0.46:0.11             4449   5515.077465   \n",
       "\n",
       "   Quality_Score  Brewhouse_Efficiency  Loss_During_Brewing  \\\n",
       "0       8.577016             89.195882             4.104988   \n",
       "1       7.420541             72.480915             2.676528   \n",
       "2       8.451365             86.322144             3.299894   \n",
       "3       9.671859             83.094940             2.136055   \n",
       "4       7.895334             88.625833             4.491724   \n",
       "\n",
       "   Loss_During_Fermentation  Loss_During_Bottling_Kegging  \n",
       "0                  3.235485                      4.663204  \n",
       "1                  4.246129                      2.044358  \n",
       "2                  3.109440                      3.033880  \n",
       "3                  4.634254                      1.489889  \n",
       "4                  2.183389                      2.990630  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas =pd.read_csv(r\"c:\\Users\\Vincenzo\\PROJECTS\\DDAM_data\\brewery\\brewery_data_complete_extended.csv\")\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID|          Brew_Date|Beer_Style| SKU|    Location|Fermentation_Time|       Temperature|          pH_Level|           Gravity|  Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|       Total_Sales|    Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+-------------------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "| 7870796|2020-01-01 00:00:19|Wheat Beer|Kegs|  Whitefield|               16|24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|        20|    5|     1:0.32:0.16|           4666|2664.7593448382822| 8.57701633109399|   89.19588216376087| 4.1049876591878345|      3.2354851724654683|           4.663204448186049|\n",
      "| 9810411|2020-01-01 00:00:31|      Sour|Kegs|  Whitefield|               13|18.086762947259544| 5.275643382756193|1.0598189516987164|5.096053082797625|        36|   14|     1:0.39:0.24|            832| 9758.801062471319|7.420540752553908|    72.4809153900275| 2.6765280953921122|      4.2461292104108574|            2.04435836917023|\n",
      "| 2623342|2020-01-01 00:00:40|Wheat Beer|Kegs| Malleswaram|               12|15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|        30|   10|     1:0.35:0.16|           2115|11721.087016274963|8.451364886803127|   86.32214396020584|  3.299893625514981|       3.109440467362847|          3.0338798378762806|\n",
      "| 8114651|2020-01-01 00:01:37|       Ale|Kegs| Rajajinagar|               17| 16.41848910394318| 5.345260585546188|1.0524314251694946|5.509243080797997|        48|   18|     1:0.35:0.15|           3173|12050.177463190277|9.671859404043175|   83.09494037181545|  2.136055116262562|       4.634254174098425|          1.4898890677148424|\n",
      "| 4579587|2020-01-01 00:01:43|     Stout|Cans|Marathahalli|               18|19.144907654338517|  4.86185374113861|1.0542961149482333|5.133624684263243|        57|   13|     1:0.46:0.11|           4449|5515.0774647529615|7.895333676172065|   88.62583302052388|  4.491723843594972|      2.1833886016455497|          2.9906302188791485|\n",
      "+--------+-------------------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(r\"c:\\Users\\Vincenzo\\PROJECTS\\DDAM_data\\brewery\\brewery_data_complete_extended.csv\", header=True, inferSchema=True)\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of df_pyspark: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "Type of df_pandas: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of df_pyspark:\", type(df_pyspark))\n",
    "print(\"Type of df_pandas:\", type(df_pandas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database\n",
    "\n",
    "- PySpark Dataframe\n",
    "- Reading The Dataset\n",
    "- Checking the Datatypes of the Column(Schema)\n",
    "- Selecting Columns And Indexing\n",
    "- Check Describe option similar to Pandas\n",
    "-  Adding Columns\n",
    "- Dropping columns\n",
    "- Renaming Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the Dataframe is: (10000000, 20)\n"
     ]
    }
   ],
   "source": [
    "rows = df_pyspark.count()\n",
    "cols = len(df_pyspark.columns)\n",
    "\n",
    "print(f'Dimension of the Dataframe is: {(rows,cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Beer_Style|\n",
      "+----------+\n",
      "|Wheat Beer|\n",
      "|      Sour|\n",
      "|Wheat Beer|\n",
      "|       Ale|\n",
      "|     Stout|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Wheat Beer\n",
       "1          Sour\n",
       "2    Wheat Beer\n",
       "3           Ale\n",
       "4         Stout\n",
       "Name: Beer_Style, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"Beer_Style\").show(5)\n",
    "\n",
    "df_pandas[\"Beer_Style\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|Beer_Style|          Brew_Date|\n",
      "+----------+-------------------+\n",
      "|Wheat Beer|2020-01-01 00:00:19|\n",
      "|      Sour|2020-01-01 00:00:31|\n",
      "|Wheat Beer|2020-01-01 00:00:40|\n",
      "|       Ale|2020-01-01 00:01:37|\n",
      "|     Stout|2020-01-01 00:01:43|\n",
      "+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer_Style</th>\n",
       "      <th>Brew_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat Beer</td>\n",
       "      <td>2020-01-01 00:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sour</td>\n",
       "      <td>2020-01-01 00:00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat Beer</td>\n",
       "      <td>2020-01-01 00:00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ale</td>\n",
       "      <td>2020-01-01 00:01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stout</td>\n",
       "      <td>2020-01-01 00:01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beer_Style            Brew_Date\n",
       "0  Wheat Beer  2020-01-01 00:00:19\n",
       "1        Sour  2020-01-01 00:00:31\n",
       "2  Wheat Beer  2020-01-01 00:00:40\n",
       "3         Ale  2020-01-01 00:01:37\n",
       "4       Stout  2020-01-01 00:01:43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"Beer_Style\", \"Brew_Date\").show(5)\n",
    "\n",
    "df_pandas[[\"Beer_Style\", \"Brew_Date\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Batch_ID: integer (nullable = true)\n",
      " |-- Brew_Date: timestamp (nullable = true)\n",
      " |-- Beer_Style: string (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Fermentation_Time: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- pH_Level: double (nullable = true)\n",
      " |-- Gravity: double (nullable = true)\n",
      " |-- Alcohol_Content: double (nullable = true)\n",
      " |-- Bitterness: integer (nullable = true)\n",
      " |-- Color: integer (nullable = true)\n",
      " |-- Ingredient_Ratio: string (nullable = true)\n",
      " |-- Volume_Produced: integer (nullable = true)\n",
      " |-- Total_Sales: double (nullable = true)\n",
      " |-- Quality_Score: double (nullable = true)\n",
      " |-- Brewhouse_Efficiency: double (nullable = true)\n",
      " |-- Loss_During_Brewing: double (nullable = true)\n",
      " |-- Loss_During_Fermentation: double (nullable = true)\n",
      " |-- Loss_During_Bottling_Kegging: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Batch_ID', 'int'),\n",
       " ('Brew_Date', 'timestamp'),\n",
       " ('Beer_Style', 'string'),\n",
       " ('SKU', 'string'),\n",
       " ('Location', 'string'),\n",
       " ('Fermentation_Time', 'int'),\n",
       " ('Temperature', 'double'),\n",
       " ('pH_Level', 'double'),\n",
       " ('Gravity', 'double'),\n",
       " ('Alcohol_Content', 'double'),\n",
       " ('Bitterness', 'int'),\n",
       " ('Color', 'int'),\n",
       " ('Ingredient_Ratio', 'string'),\n",
       " ('Volume_Produced', 'int'),\n",
       " ('Total_Sales', 'double'),\n",
       " ('Quality_Score', 'double'),\n",
       " ('Brewhouse_Efficiency', 'double'),\n",
       " ('Loss_During_Brewing', 'double'),\n",
       " ('Loss_During_Fermentation', 'double'),\n",
       " ('Loss_During_Bottling_Kegging', 'double')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+--------+---------------+-----------------+------------------+-------------------+--------------------+-------------------+------------------+-----------------+----------------+-----------------+------------------+------------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|summary|          Batch_ID|Beer_Style|     SKU|       Location|Fermentation_Time|       Temperature|           pH_Level|             Gravity|    Alcohol_Content|        Bitterness|            Color|Ingredient_Ratio|  Volume_Produced|       Total_Sales|     Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+-------+------------------+----------+--------+---------------+-----------------+------------------+-------------------+--------------------+-------------------+------------------+-----------------+----------------+-----------------+------------------+------------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|  count|          10000000|  10000000|10000000|       10000000|         10000000|          10000000|           10000000|            10000000|           10000000|          10000000|         10000000|        10000000|         10000000|          10000000|          10000000|            10000000|           10000000|                10000000|                    10000000|\n",
      "|   mean|         4999999.5|      NULL|    NULL|           NULL|        14.500898|19.999898511018827|  4.999940543893489|  1.0550028700788692|  5.249709006579308|        39.4961996|       11.9993459|            NULL|     2749.0309594|10497.785343940232| 7.999825148192516|   80.00091934182497|  3.000081497042524|       3.000002413212497|          3.0001587106749747|\n",
      "| stddev|2886751.4902856858|      NULL|    NULL|           NULL|2.872006096518228|2.8870297120328576|0.28863762894103545|0.014434649211836703|0.43296144791729213|11.545572488490313|4.321170228005893|            NULL|1299.078133259011| 5485.995544804044|1.1546793056214646|  5.7749295785811645| 1.1547483756083143|      1.1548266863212513|          1.1547186092997934|\n",
      "|    min|                 0|       Ale| Bottles|Electronic City|               10|15.000001163771435|  4.500000005935603|  1.0300000027891478|  4.500000235642255|                20|                5|     1:0.20:0.10|              500|1000.0009630942443| 6.000000644037316|   70.00000702282782|  1.000000399567285|      1.0000008690556794|          1.0000002095815321|\n",
      "|    max|           9999999|Wheat Beer|   Pints|      Yelahanka|               19|24.999998289887966|  5.499999818305633|  1.0799999980323736|  5.999999932506248|                59|               19|     1:0.50:0.30|             4999| 19999.99964105241| 9.999998860537378|   89.99999982126904|  4.999999841589812|       4.999999816405875|           4.999999721589095|\n",
      "+-------+------------------+----------+--------+---------------+-----------------+------------------+-------------------+--------------------+-------------------+------------------+-----------------+----------------+-----------------+------------------+------------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding columns to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\"Bitterness + 2\", df_pyspark[\"Bitterness\"] + 2)\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\"test\", F.concat(df_pyspark[\"SKU\"], F.lit(\"2\")))\n",
    "df_pyspark.show(5)\n",
    "#spark does not support concatenation of strings columns via + so u have to use the concat function with the literal function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.drop(\"test\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.drop(\"Bitterness + 2\", \"Temperature\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.withColumnRenamed(\"Bitterness + 2\", \"new_name\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "- dropping columns\n",
    "- dropping rows\n",
    "- various parameter in dropping functionalities\n",
    "- handling missing values by:\n",
    "    - mean\n",
    "    - median\n",
    "    - mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(r\"c:\\Users\\Vincenzo\\PROJECTS\\DDAM_data\\test\\test2.csv\", header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.dropna().show()\n",
    "df_pyspark.na.drop().show() \n",
    "\n",
    "#equivalent options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop options\n",
    "\n",
    "by default it's any\n",
    "\n",
    "- how:\n",
    "    - any\n",
    "    - all\n",
    "- threshold\n",
    "- subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = \"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(how = \"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.drop(subset = [\"experience\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.na.fill(\"Missing values\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a specific column\n",
    "df_pyspark.na.fill(\"Missing values\", \"experience\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple columns (its not showing but it shoudl work)\n",
    "df_pyspark.na.fill(\"Missing values\", [\"experience\", \"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"age\", \"Experience\", \"Salary\"], \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in [\"age\", \"Experience\", \"Salary\"]]\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
